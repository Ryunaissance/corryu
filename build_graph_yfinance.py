"""
yfinance ì—†ì´ Yahoo Finance API ì§ì ‘ í˜¸ì¶œë¡œ ê·¸ë˜í”„ ë°ì´í„° ìƒì„±
  - requests + ThreadPoolExecutor ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ
  - ì›”ê°„ ìˆ˜ìµë¥  ìƒê´€í–‰ë ¬ ê³„ì‚° â†’ output/graph_data.json ì €ì¥

ì‚¬ìš©ë²•:
  python build_graph_yfinance.py
"""
import json
import os
import sys
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import pandas as pd
import requests

ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(ROOT, 'src'))
from config import SECTOR_DEFS

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RANGE         = 'max'        # ìƒì¥ì¼ë¶€í„° ìµœì‹  ë°ì´í„°ê¹Œì§€ ì „ì²´ ì´ë ¥ ì‚¬ìš©
MIN_MONTHS    = 24           # ìƒê´€ê³„ìˆ˜ ìµœì†Œ ìœ íš¨ ê¸°ê°„
STORE_MIN_R   = 0.85         # JSON ì €ì¥ ìµœì†Œ r
MAX_WORKERS   = 12           # ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ìŠ¤ë ˆë“œ ìˆ˜
RETRY_MAX     = 3            # ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
ETF_DATA_JSON = os.path.join(ROOT, 'output', 'etf_data.json')
OUT_JSON      = os.path.join(ROOT, 'output', 'graph_data.json')

SECTOR_COLORS = {
    'S01': '#60a5fa', 'S02': '#a78bfa', 'S03': '#34d399',
    'S04': '#fbbf24', 'S05': '#f87171', 'S06': '#fb923c',
    'S07': '#94a3b8', 'S08': '#fde047', 'S09': '#38bdf8',
    'S10': '#a3e635', 'S11': '#4ade80', 'S12': '#2dd4bf',
    'S13': '#f472b6', 'S14': '#818cf8', 'S15': '#67e8f9',
    'S16': '#fdba74', 'S17': '#86efac', 'S18': '#fcd34d',
    'S19': '#6b7280', 'S20': '#c084fc', 'S21': '#f59e0b',
    'S22': '#ef4444', 'S24': '#475569',
}

# ìš”ì²­ í—¤ë” (ë´‡ ì°¨ë‹¨ ìš°íšŒ)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'application/json',
}

_print_lock = threading.Lock()


def safe_print(msg):
    with _print_lock:
        print(msg, flush=True)


def fetch_ticker(session, ticker):
    """Yahoo Finance chart APIë¡œ ì›”ê°„ ì¢…ê°€ Series ë°˜í™˜. ì‹¤íŒ¨ ì‹œ None."""
    url = (
        f'https://query2.finance.yahoo.com/v8/finance/chart/{ticker}'
        f'?range={RANGE}&interval=1mo&includeAdjustedClose=true'
    )
    for attempt in range(RETRY_MAX):
        try:
            r = session.get(url, headers=HEADERS, timeout=15)
            if r.status_code == 429:
                time.sleep(2 ** attempt)
                continue
            if r.status_code != 200:
                return None
            data = r.json()
            result = data.get('chart', {}).get('result')
            if not result:
                return None
            ts    = result[0]['timestamp']
            meta  = result[0].get('meta', {})
            # adjclose ìš°ì„ , ì—†ìœ¼ë©´ close
            indicators = result[0].get('indicators', {})
            adj = indicators.get('adjclose', [{}])
            if adj and adj[0].get('adjclose'):
                prices = adj[0]['adjclose']
            else:
                prices = indicators.get('quote', [{}])[0].get('close', [])
            if not prices:
                return None
            idx = pd.to_datetime(ts, unit='s', utc=True).tz_convert(None)
            s = pd.Series(prices, index=idx, name=ticker, dtype=float)
            s = s.dropna()
            return s if len(s) >= MIN_MONTHS else None
        except Exception:
            time.sleep(1)
    return None


def download_all(tickers):
    """ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ. {ticker: Series} ë”•ì…”ë„ˆë¦¬ ë°˜í™˜."""
    results = {}
    done = 0
    total = len(tickers)

    session = requests.Session()

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:
        futures = {pool.submit(fetch_ticker, session, tk): tk for tk in tickers}
        for fut in as_completed(futures):
            tk = futures[fut]
            done += 1
            s = fut.result()
            if s is not None:
                results[tk] = s
            if done % 100 == 0 or done == total:
                safe_print(f'   {done}/{total}  (ì„±ê³µ: {len(results)}ê°œ)')

    return results


def build_graph_data(corr, meta):
    tickers = list(corr.columns)
    n = len(tickers)

    nodes = []
    for tk in tickers:
        m = meta.get(tk, {})
        nodes.append({'id': tk, 'n': m.get('n', tk), 's': m.get('s', 'S24'), 'a': m.get('a', 0.0)})

    print(f'   ì—£ì§€ ê³„ì‚° ì¤‘ (r â‰¥ {STORE_MIN_R})...')
    arr = corr.values.astype(np.float32)
    np.fill_diagonal(arr, np.nan)
    ri, ci = np.triu_indices(n, k=1)
    rv = arr[ri, ci]
    mask = (rv >= STORE_MIN_R) & ~np.isnan(rv)
    ri, ci, rv = ri[mask], ci[mask], rv[mask]
    links = [
        {'s': tickers[int(i)], 't': tickers[int(j)], 'r': round(float(r), 3)}
        for i, j, r in zip(ri, ci, rv)
    ]
    print(f'   ì—£ì§€ ìˆ˜: {len(links):,}ê°œ')

    sectors = {
        sid: {
            'name': sdef['name'], 'name_en': sdef['name_en'],
            'color': SECTOR_COLORS.get(sid, '#888888'), 'ac': sdef['asset_class'],
        }
        for sid, sdef in SECTOR_DEFS.items()
    }
    return {
        'nodes': nodes, 'links': links, 'sectors': sectors,
        'meta': {'n_nodes': len(nodes), 'n_links_stored': len(links), 'store_min_r': STORE_MIN_R},
    }


def main():
    t0 = time.time()

    print('ğŸ“‹ ETF ë©”íƒ€ë°ì´í„° ë¡œë“œ...')
    with open(ETF_DATA_JSON, encoding='utf-8') as f:
        db = json.load(f)
    meta = {}
    tickers = []
    for sid, etfs in db['allData'].items():
        for e in etfs:
            tk = e['ticker']
            meta[tk] = {'n': e['name'], 's': sid, 'a': round(e.get('aum', 0) / 1e9, 2)}
            tickers.append(tk)
    print(f'   {len(tickers)}ê°œ í‹°ì»¤')

    print(f'\nğŸ“¡ Yahoo Finance ì›”ê°„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë³‘ë ¬ {MAX_WORKERS}ìŠ¤ë ˆë“œ)...')
    price_data = download_all(tickers)
    print(f'   ì™„ë£Œ: {len(price_data)}/{len(tickers)}ê°œ ì„±ê³µ')

    if len(price_data) < 50:
        print('âŒ ì„±ê³µí•œ í‹°ì»¤ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.')
        sys.exit(1)

    print('\nğŸ“Š ìƒê´€í–‰ë ¬ ê³„ì‚° ì¤‘...')
    df = pd.DataFrame(price_data)
    # ETFë§ˆë‹¤ Yahoo Finance ì›”ê°„ bar ì‹œì‘ ë‚ ì§œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´(IPOì¼ ë“±)
    # outer-join ì‹œ ì¤‘ê°„ì— NaN í–‰ì´ ìƒê¸°ë©´ pct_changeê°€ ìˆ˜ìµë¥ ì„ ì˜ëª» NaNìœ¼ë¡œ ë§Œë“ ë‹¤.
    # resample('ME').last()ë¡œ ì›”ë§ ê¸°ì¤€ í†µì¼ â†’ ëª¨ë“  ETF ë™ì¼ ë‚ ì§œ ê²©ì ì‚¬ìš©.
    df = df.resample('ME').last()
    df_ret = df.pct_change(fill_method=None)
    valid = df_ret.columns[df_ret.count() >= MIN_MONTHS]
    df_ret = df_ret[valid]
    print(f'   ìœ íš¨ í‹°ì»¤(â‰¥{MIN_MONTHS}ê°œì›”): {len(valid)}ê°œ')
    corr = df_ret.corr(method='pearson', min_periods=MIN_MONTHS)

    print('\nğŸ”— ê·¸ë˜í”„ ë°ì´í„° ìƒì„± ì¤‘...')
    out = build_graph_data(corr, meta)

    os.makedirs(os.path.dirname(OUT_JSON), exist_ok=True)
    with open(OUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(out, f, ensure_ascii=False, separators=(',', ':'))

    size_mb = os.path.getsize(OUT_JSON) / 1024 ** 2
    elapsed = time.time() - t0
    print(f'\nâœ… ì €ì¥ ì™„ë£Œ: {OUT_JSON}')
    print(f'   ë…¸ë“œ {out["meta"]["n_nodes"]:,}ê°œ | ì—£ì§€ {out["meta"]["n_links_stored"]:,}ê°œ | {size_mb:.1f} MB')
    print(f'   ì†Œìš” ì‹œê°„: {elapsed:.0f}ì´ˆ')
    print()
    print('ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:')
    print('   git add output/graph_data.json')
    print("   git commit -m 'feat: graph_data.json ì¶”ê°€'")
    print('   git push')


if __name__ == '__main__':
    main()
